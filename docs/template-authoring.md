# Template Authoring Guide

Learn how to create high-quality prompt templates that integrate seamlessly with the meta-prompt optimization infrastructure.

---

## Table of Contents

1. [When to Create a New Template](#when-to-create-a-new-template)
2. [Template Anatomy](#template-anatomy)
3. [Step-by-Step Creation Process](#step-by-step-creation-process)
4. [Variable Naming Conventions](#variable-naming-conventions)
5. [Writing Effective Template Bodies](#writing-effective-template-bodies)
6. [Classification Keyword Selection](#classification-keyword-selection)
7. [Testing Your Template](#testing-your-template)
8. [Real Example Walkthrough](#real-example-walkthrough)
9. [Best Practices](#best-practices)
10. [Common Pitfalls](#common-pitfalls)

---

## When to Create a New Template

### Frequency Thresholds

Create a new template when:

1. **High Frequency:** You encounter the same pattern 15+ times
2. **Clear Pattern:** The task structure is consistent and repeatable
3. **Token Savings:** The pattern consumes >1000 tokens when generated by LLM
4. **Distinct Category:** It doesn't fit existing templates well (confidence <70%)

### Don't Create a Template If:

- The pattern appears <10 times
- Each instance is highly unique
- The pattern is too simple (<3 variables)
- It overlaps heavily with existing templates

### Current Template Capacity

- **Current:** 6 templates
- **Recommended maximum:** 15-20 templates before classification complexity increases
- **Sweet spot:** 8-12 templates for most projects

---

## Template Anatomy

Every template consists of two parts:

### 1. YAML Frontmatter (Metadata)

```yaml
---
template_name: your-template-name
category: broad-category
keywords: [keyword1, keyword2, keyword3, ...]
complexity: simple|intermediate|complex
variables: [VAR1, VAR2, VAR3, ...]
version: 1.0
description: One-line description of what this template does
variable_descriptions:  # Optional but recommended
  VAR1: "Explanation of what this variable represents"
  VAR2: "Explanation of what this variable represents"
---
```

### 2. Template Body (Prompt Content)

```markdown
Your prompt content goes here.

Use {$VARIABLE_NAME} placeholders for dynamic content.

<structured>
You can use XML tags for organization.
</structured>

Include clear instructions and examples.
```

---

## Step-by-Step Creation Process

### Step 1: Identify the Pattern

Collect 3-5 examples of the task you want to templatize:

**Example Pattern:** Sentiment Analysis
```
"Analyze the sentiment of this product review: [review text]"
"What's the sentiment of this tweet: [tweet]"
"Determine if this email is positive, negative, or neutral: [email]"
```

**Common structure:**
- Action: Analyze sentiment
- Input: Text to analyze
- Output: Positive/negative/neutral classification

### Step 2: Extract Variables

Identify what changes between instances:

- `TEXT_TO_ANALYZE`: The content being analyzed
- `OUTPUT_FORMAT`: (optional) How to present the result

### Step 3: Choose Template Name and Category

**Template name:** `sentiment-analysis` (lowercase, hyphenated)
**Category:** `analysis` (groups with similar templates)

### Step 4: Select Keywords

Keywords should match how users naturally describe the task:

**Strong indicators:** (75% confidence)
- "sentiment"
- "emotion"
- "feeling"

**Supporting keywords:** (8% each)
- "positive", "negative", "neutral"
- "analyze", "determine", "classify"
- "review", "tweet", "feedback", "email"

### Step 5: Create Template File

```bash
cd .claude/templates
cp custom.md sentiment-analysis.md
```

Edit the file:

```yaml
---
template_name: sentiment-analysis
category: analysis
keywords: [sentiment, emotion, feeling, positive, negative, neutral, analyze, tone, mood]
complexity: simple
variables: [TEXT_TO_ANALYZE]
version: 1.0
description: Analyze sentiment of text as positive, negative, or neutral
variable_descriptions:
  TEXT_TO_ANALYZE: "The text content to analyze (review, tweet, email, etc.)"
---

You will analyze the sentiment of the provided text.

<text>
{$TEXT_TO_ANALYZE}
</text>

<instructions>
1. Read the text carefully
2. Identify emotional tone and word choice
3. Classify as: POSITIVE, NEGATIVE, or NEUTRAL
4. Provide brief justification
</instructions>

<output_format>
**Sentiment:** [POSITIVE/NEGATIVE/NEUTRAL]
**Confidence:** [High/Medium/Low]
**Reasoning:** [Brief explanation]
</output_format>

<examples>
**Example 1:**
Text: "This product exceeded my expectations! Fast shipping too."
Sentiment: POSITIVE
Confidence: High
Reasoning: Enthusiastic language ("exceeded expectations"), exclamation point, additional positive note about shipping.

**Example 2:**
Text: "The item arrived. It works as described."
Sentiment: NEUTRAL
Confidence: High
Reasoning: Factual statements without emotional language. No positive or negative indicators.
</examples>

Begin your analysis immediately without preamble.
```

### Step 6: Update Classification Logic

Edit `.claude/commands/scripts/template-selector.sh`:

Find the keyword arrays (around line 83) and add:

```bash
# Around line 95 (add new category)
local -A sentiment_keywords=(
    [strong]="sentiment|emotion|feeling"
    [supporting]="positive|negative|neutral|analyze|tone|mood|review|tweet|feedback"
)

# Around line 130 (add scoring logic)
score_sentiment=$(score_category "sentiment" "$task_lower")
if [ "$score_sentiment" -gt "$best_score" ]; then
    best_template="sentiment-analysis"
    best_score="$score_sentiment"
fi
```

### Step 7: Validate

```bash
.claude/commands/scripts/validate-templates.sh sentiment-analysis
```

**Expected output:**
```
=== Template Validation ===
Validating: sentiment-analysis
  âœ“ Has valid frontmatter
  âœ“ Has required field: template_name
  âœ“ Has required field: category
  âœ“ Has required field: keywords
  âœ“ Has required field: complexity
  âœ“ Has required field: variables
  âœ“ Has required field: version
  âœ“ Has required field: description
  âœ“ All declared variables used in template
  âœ“ All used variables declared
  âœ“ XML tags are balanced
  âœ“ Template has content
PASSED: sentiment-analysis
```

### Step 8: Test Classification

```bash
DEBUG=1 .claude/commands/scripts/template-selector.sh \
  "Analyze the sentiment of this product review"
```

**Expected output:**
```
sentiment-analysis
Confidence: 83%
Threshold: 70%
```

### Step 9: Add Integration Tests

Edit `.claude/commands/scripts/test-integration.sh`:

Add test case in Phase 3 (Template Selection Accuracy):

```bash
run_test "Sentiment analysis task routes to sentiment-analysis template" \
    ".claude/commands/scripts/template-selector.sh 'Analyze sentiment of this tweet'" \
    "sentiment-analysis"
```

### Step 10: Test Full Workflow

```bash
# Run complete test suite
.claude/commands/scripts/test-integration.sh

# Test actual usage
/create-prompt "Analyze the sentiment of this movie review: [review text]"
```

### Step 11: Update Documentation

1. Add to `docs/examples.md` (new example)
2. Update `docs/architecture-overview.md:186` (template table)
3. Update `README.md:138` (template list)
4. Commit with descriptive message

---

## Variable Naming Conventions

### Naming Rules

1. **ALL_CAPS_SNAKE_CASE:** `USER_INPUT`, `DOCUMENT_TEXT`, `API_ENDPOINT`
2. **Descriptive:** `TEXT_TO_ANALYZE` not `TEXT`, `SOURCE_CODE` not `CODE`
3. **Consistent:** Use same name for same concept across templates
4. **No abbreviations:** `CLASSIFICATION_CRITERIA` not `CLASS_CRIT`

### Common Variable Names

| Variable | Use Case | Example |
|----------|----------|---------|
| `ITEM1`, `ITEM2` | Comparisons | Simple classification |
| `DOCUMENT`, `QUESTION` | Q&A | Document analysis |
| `TASK_REQUIREMENTS`, `TARGET_PATTERNS` | Code work | Refactoring |
| `TASK_DESCRIPTION`, `AVAILABLE_FUNCTIONS` | Tool use | Function calling |
| `ROLE_DESCRIPTION`, `CONTEXT`, `RULES` | Agents | Interactive dialogue |
| `TEXT_TO_ANALYZE`, `OUTPUT_FORMAT` | Analysis | Sentiment, summarization |

### Variable Descriptions

Always include `variable_descriptions` in frontmatter:

```yaml
variable_descriptions:
  SOURCE_CODE: "The code to be analyzed or refactored (function, class, or file)"
  MODIFICATION_GOAL: "What to change (e.g., 'improve performance', 'add error handling')"
```

This helps users understand what to provide for each variable.

---

## Writing Effective Template Bodies

### Structure Your Template

```markdown
[1. Context setting - what role is the LLM playing?]
You are a [role] helping with [task].

[2. Input presentation - XML tags recommended]
<input_name>
{$VARIABLE}
</input_name>

[3. Clear instructions - numbered or bulleted]
**Instructions:**
1. First step
2. Second step
3. Third step

[4. Output format - show exact format expected]
**Format:**
<output>
[Expected structure]
</output>

[5. Examples - concrete demonstrations]
**Example:**
Input: [example input]
Output: [example output]

[6. Edge case handling - what to do if...]
If [condition], then [action].

[7. Final directive - how to begin]
Begin your response immediately without preamble.
```

### Best Practices for Template Body

**DO:**
- âœ“ Use XML tags for structured input/output
- âœ“ Provide concrete examples
- âœ“ Be explicit about output format
- âœ“ Include edge case handling
- âœ“ Use clear, imperative language
- âœ“ Number steps for complex processes

**DON'T:**
- âœ— Use vague instructions ("try to", "maybe")
- âœ— Assume the LLM knows context
- âœ— Mix multiple unrelated tasks
- âœ— Over-explain (keep it concise)
- âœ— Use placeholder variables in examples

### Complexity Levels

**Simple** (â‰¤3 steps):
```markdown
1. Read input
2. Perform action
3. Output result
```

**Intermediate** (4-6 steps):
```markdown
1. Read input
2. Extract information
3. Analyze against criteria
4. Format output
5. Cite sources
```

**Complex** (7+ steps):
```markdown
1. Plan with TodoWrite
2. Search for target patterns
3. Read files
4. Make modifications
5. Test changes
6. Update todos
7. Report results
```

---

## Classification Keyword Selection

### Keyword Strategy

**Goal:** Achieve 90%+ correct classifications with 70% confidence threshold.

### Types of Keywords

**1. Strong Indicators** (75% base confidence)
- Unique to this template
- Rare in other contexts
- Examples: "refactor" â†’ code, "sentiment" â†’ analysis, "tutor" â†’ dialogue

**2. Supporting Keywords** (8% each)
- Common in this domain
- Add confidence when combined
- Examples: "code", "function", "file" for code templates

**3. Avoid**
- Generic words ("the", "a", "help")
- Ambiguous terms that appear in multiple templates
- Rare synonyms users won't use

### Keyword Selection Process

1. **Collect real examples:** 20+ task descriptions from actual use
2. **Extract common words:** What words appear in 80%+ of examples?
3. **Filter for specificity:** Remove words that appear in other templates
4. **Test with DEBUG:** Verify classification confidence
5. **Iterate:** Add/remove keywords based on real usage

### Testing Keywords

```bash
# Test multiple variations
DEBUG=1 .claude/commands/scripts/template-selector.sh "refactor the code"
DEBUG=1 .claude/commands/scripts/template-selector.sh "modify the function"
DEBUG=1 .claude/commands/scripts/template-selector.sh "update the class"

# All should route to code-refactoring with >70% confidence
```

---

## Testing Your Template

### Validation Tests (Automated)

```bash
# Validates structure, variables, XML tags
.claude/commands/scripts/validate-templates.sh your-template-name
```

**What it checks:**
- âœ“ YAML frontmatter present and valid
- âœ“ All required fields exist
- âœ“ Variables declared match variables used
- âœ“ XML tags balanced
- âœ“ Template has non-empty content

### Classification Tests

```bash
# Test that tasks route correctly
DEBUG=1 .claude/commands/scripts/template-selector.sh "task description"
```

**Success criteria:**
- Confidence â‰¥ 70% for matching tasks
- Confidence < 70% for non-matching tasks

### Integration Tests

Add to `.claude/commands/scripts/test-integration.sh`:

```bash
run_test "Your template routes correctly" \
    ".claude/commands/scripts/template-selector.sh 'example task'" \
    "your-template-name"
```

### Manual Testing

```bash
# Test full workflow
/create-prompt "actual task description"

# Verify:
# 1. Correct template selected
# 2. Variables properly substituted
# 3. Output makes sense
```

---

## Real Example Walkthrough

Let's create a "code-comparison" template from scratch.

### Step 1: Identify the Pattern

Users frequently ask:
- "What's the difference between these two code snippets?"
- "Compare implementation A vs implementation B"
- "Which approach is better: [code1] or [code2]?"

### Step 2: Extract Variables

- `CODE_SNIPPET_1`: First code sample
- `CODE_SNIPPET_2`: Second code sample
- `COMPARISON_CRITERIA`: What to compare (performance, readability, correctness)

### Step 3: Create Template

**File:** `.claude/templates/code-comparison.md`

```yaml
---
template_name: code-comparison
category: analysis
keywords: [difference, compare, versus, vs, better, worse, implementation, approach, alternative]
complexity: intermediate
variables: [CODE_SNIPPET_1, CODE_SNIPPET_2, COMPARISON_CRITERIA]
version: 1.0
description: Compare two code snippets across specified criteria
variable_descriptions:
  CODE_SNIPPET_1: "First code snippet to compare"
  CODE_SNIPPET_2: "Second code snippet to compare"
  COMPARISON_CRITERIA: "What to compare (e.g., performance, readability, maintainability)"
---

You are a code review expert comparing two implementations.

<code_1>
{$CODE_SNIPPET_1}
</code_1>

<code_2>
{$CODE_SNIPPET_2}
</code_2>

<criteria>
{$COMPARISON_CRITERIA}
</criteria>

**Analysis Process:**
1. Understand what each code snippet does
2. Evaluate both against the comparison criteria
3. Identify strengths and weaknesses of each
4. Provide a recommendation if applicable

**Output Format:**
### Code Snippet 1
- Strengths: [list]
- Weaknesses: [list]
- Rating: [1-5 on criteria]

### Code Snippet 2
- Strengths: [list]
- Weaknesses: [list]
- Rating: [1-5 on criteria]

### Recommendation
[Which is better for the given criteria, or when to use each]

**Important:**
- Be objective and specific
- Cite actual code when explaining
- Consider edge cases and trade-offs

Begin your comparison immediately.
```

### Step 4: Update Classification

Edit `.claude/commands/scripts/template-selector.sh`:

```bash
# Add to keyword arrays (around line 90)
local -A code_comparison_keywords=(
    [strong]="difference|compare|versus|vs"
    [supporting]="better|worse|implementation|approach|alternative|snippet"
)

# Add scoring (around line 140)
score_code_comparison=$(score_category "code_comparison" "$task_lower")
if [ "$score_code_comparison" -gt "$best_score" ]; then
    best_template="code-comparison"
    best_score="$score_code_comparison"
fi
```

### Step 5: Validate

```bash
.claude/commands/scripts/validate-templates.sh code-comparison
# Should pass all checks
```

### Step 6: Test

```bash
DEBUG=1 .claude/commands/scripts/template-selector.sh \
  "Compare these two implementations for readability"

# Expected: code-comparison, Confidence: 83%+
```

### Step 7: Add Test Case

```bash
# In test-integration.sh, Phase 3
run_test "Code comparison task routes correctly" \
    ".claude/commands/scripts/template-selector.sh 'Compare implementation A vs B'" \
    "code-comparison"
```

### Step 8: Document

Update:
- `README.md:138` - Add to template list
- `docs/architecture-overview.md:186` - Add to template table
- `docs/examples.md` - Add example usage
- Git commit with clear message

---

## Best Practices

### Template Design

1. **Single Responsibility:** Each template should do one thing well
2. **Clear Examples:** Include 2-3 concrete examples in template body
3. **Explicit Output Format:** Show exactly what output should look like
4. **Edge Case Handling:** Address "what if" scenarios
5. **Progressive Disclosure:** Simple instructions first, details later

### Keyword Selection

1. **User Language:** Use words users naturally say, not technical jargon
2. **Balanced Coverage:** 3-5 strong indicators + 8-12 supporting keywords
3. **Test Variations:** Try synonyms and phrasings
4. **Monitor False Positives:** If template triggers incorrectly, refine keywords

### Variables

1. **Minimal Set:** Fewest variables possible (3-5 ideal)
2. **Optional Variables:** Use conditional text for optional elements
3. **Clear Names:** Self-documenting variable names
4. **Descriptions:** Always explain what each variable represents

### Maintenance

1. **Version Bumps:** Increment version when changing variables or structure
2. **Changelog:** Document changes in git commit messages
3. **Backwards Compatibility:** Don't break existing usage if possible
4. **Quarterly Review:** Revisit template effectiveness every 3 months

---

## Common Pitfalls

### Pitfall 1: Too Many Variables

**Problem:** Template with 8+ variables becomes hard to use
**Solution:** Combine related variables or split into multiple templates

### Pitfall 2: Overlapping Keywords

**Problem:** Multiple templates match the same task
**Solution:** Use more specific strong indicators, refine supporting keywords

### Pitfall 3: Too Generic

**Problem:** Template tries to cover too many use cases
**Solution:** Split into specialized templates (better UX)

### Pitfall 4: Too Specific

**Problem:** Template only works for one exact scenario
**Solution:** Generalize slightly or keep as custom (no template needed)

### Pitfall 5: Poor Examples

**Problem:** Examples in template are abstract or confusing
**Solution:** Use concrete, realistic examples from actual use cases

### Pitfall 6: Inconsistent Format

**Problem:** Template doesn't follow established patterns
**Solution:** Copy structure from existing templates, maintain consistency

### Pitfall 7: Missing Validation

**Problem:** Template deployed without testing
**Solution:** Always run validation + integration tests before committing

---

## Resources

### Template Examples
- Simple: `.claude/templates/simple-classification.md`
- Intermediate: `.claude/templates/document-qa.md`
- Complex: `.claude/templates/code-refactoring.md`

### Scripts
- Validation: `.claude/commands/scripts/validate-templates.sh`
- Classification: `.claude/commands/scripts/template-selector.sh`
- Processing: `.claude/commands/scripts/template-processor.sh`
- Testing: `.claude/commands/scripts/test-integration.sh`

### Documentation
- [Architecture Overview](architecture-overview.md) - Template system design
- [Design Decisions](design-decisions.md) - Why templates work this way
- [Infrastructure Guide](infrastructure.md) - Operational details
- [Examples](examples.md) - Real-world template usage

---

## Getting Help

**Questions? Issues?**
1. Review existing templates for inspiration
2. Test with `DEBUG=1` to see classification behavior
3. Run validation early and often
4. See [CONTRIBUTING.md](../CONTRIBUTING.md) for support channels

Happy template authoring! ðŸŽ¨
